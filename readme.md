#Action Recognition - Sign Language Prediction CV Project
This is a Github project that focuses on predicting sign language using a Long Short-Term Memory (LSTM) model for action recognition.

#Objective
The objective of this project is to create a system that can accurately predict sign language using computer vision techniques. The LSTM model is used to analyze sequences of frames from a video and predict the sign language being displayed. The project can be used for educational purposes, as well as for creating assistive technology for people who are deaf or hard of hearing.

#Architecture
The architecture of the system is based on a sequence model that uses an LSTM to analyze frames from a video. The frames are preprocessed to extract features using a convolutional neural network (CNN), and the features are then fed into the LSTM for prediction.

#Dependencies
The project requires the following dependencies:
Python 3
TensorFlow 2.4
OpenCV
mediapipe
Numpy